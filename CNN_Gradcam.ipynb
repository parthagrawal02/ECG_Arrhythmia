{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnwYXS9Kl3Wy"
      },
      "outputs": [],
      "source": [
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import wfdb\n",
        "import re\n",
        "from os.path import exists\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cQ6oNGEZo3-g",
        "outputId": "00e76c16-60d6-45a1-c443-8affb4018826"
      },
      "outputs": [],
      "source": [
        "dataset = []\n",
        "y = []\n",
        "for n in range(1, 10):\n",
        "    for j in range(0, 10):\n",
        "        for i in range(1, 1000):\n",
        "            if(exists('physionet/WFDBRecords/' + f\"{n:02}\" +  '/' + f\"{n:02}\" + str(j) +  '/JS' + f\"{ 1000*(n-1) + 100*(j) + i :05}\"  + '.hea')):\n",
        "                try:\n",
        "                    ecg_record = wfdb.rdsamp('physionet/WFDBRecords/' + f\"{n:02}\" +  '/' + f\"{n:02}\" + str(j) +  '/JS' + f\"{ 1000*(n-1) + 100*(j) + i :05}\")\n",
        "                except ValueError:\n",
        "                    continue\n",
        "                ecg = torch.from_numpy(ecg_record[0])\n",
        "                ecg_record[1]['comments'][2]\n",
        "                numbers = re.findall(r'\\d+', ecg_record[1]['comments'][2])\n",
        "                output_array = list(map(int, numbers))\n",
        "                dataset.append(ecg_record[0])\n",
        "                y.append(output_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A226tlsl3W0"
      },
      "outputs": [],
      "source": [
        "dataset = np.array(dataset)\n",
        "dataset = dataset.astype( np.double, copy=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3LAKgI7l3W1"
      },
      "outputs": [],
      "source": [
        "b = np.zeros([len(y),len(max(y,key = lambda x: len(x)))])\n",
        "for i,j in enumerate(y):\n",
        "    b[i][0:len(j)] = j\n",
        "b = np.array(b, dtype= np.double)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = {\n",
        "        426177001: 1,\n",
        "        426783006: 2,\n",
        "        164889003: 3,\n",
        "        427084000: 4,\n",
        "        164890007: 5,\n",
        "        427393009: 6,\n",
        "        426761007: 7,\n",
        "        713422000: 8,\n",
        "        233896004: 9,\n",
        "        233897008: 0\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGKLJW80l3W1",
        "outputId": "fef6c5eb-0d08-46ed-b405-dd8b70c1913d"
      },
      "outputs": [],
      "source": [
        "max(y ,key = lambda x: len(x))\n",
        "lengths = y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1m-fGgm66wdh"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.astype(np.double)\n",
        "X = torch.from_numpy(dataset[:, :, :])\n",
        "print(X.shape)\n",
        "X = X.permute(0, 2, 1)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQSHlswK8fnx"
      },
      "outputs": [],
      "source": [
        "labels = list(set(i for j in b for i in j))\n",
        "dict = {}\n",
        "for i, j in enumerate(labels):\n",
        "    dict[j] = i\n",
        "\n",
        "for i in range(len(y)):\n",
        "    for j in y[i]:\n",
        "        if int(j) in classes:\n",
        "            # classes[int(j)] += 1\n",
        "            print('a')\n",
        "            y[i] = j\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(y)):\n",
        "    y[i] = classes[y[i]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf8v0Apy8hZl"
      },
      "outputs": [],
      "source": [
        "# def to_onehot(labels, n_categories, dtype=torch.double):\n",
        "#     batch_size = len(labels)\n",
        "#     one_hot_labels = torch.zeros(size=(batch_size, n_categories), dtype=dtype)\n",
        "#     for i, label in enumerate(labels):\n",
        "#         # Subtract 1 from each LongTensor because your\n",
        "#         # indexing starts at 1 and tensor indexing starts at 0\n",
        "#         label = torch.LongTensor(label) - 1\n",
        "#         one_hot_labels[i] = one_hot_labels[i].scatter_(dim=0, index=label, value=1.)\n",
        "#     return one_hot_labels\n",
        "\n",
        "# Y = torch.nn.functional.one_hot(torch.from_numpy(np.array(y)), num_classes= 10) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UM0PUNKl3W2"
      },
      "outputs": [],
      "source": [
        "train_size = 7500\n",
        "test_size = 1400\n",
        "dataset = dataset.astype(np.double)\n",
        "Y = torch.from_numpy(np.array(y))\n",
        "X_train = (X[:train_size, :, :])\n",
        "Y_train = (Y[:train_size])\n",
        "X_test = (X[train_size:test_size + train_size, :, :])\n",
        "Y_test = (Y[train_size:test_size + train_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrmwT_aC-68t"
      },
      "outputs": [],
      "source": [
        "train_batch_size = 200\n",
        "test_batch_size = 100\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T-fu2RFl3W2"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class myModule(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, subsample=False, c_out=-1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(c_in, 16, kernel_size=5, padding=1, stride=1, bias=False),  # No bias needed as the Batch Norm handles it\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv1d(16, 16, kernel_size=5, padding=1, stride=1, bias=False),  # No bias needed as the Batch Norm handles it\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv1d(16, 32, kernel_size=5, padding=1, stride=1, bias=False),  # No bias needed as the Batch Norm handles it\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(4),\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv1d(32, 32, kernel_size=3, padding=1, stride=1, bias=False),  # No bias needed as the Batch Norm handles it\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "        )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv1d(32, 64, kernel_size=3, padding=1, stride=1, bias=False),  # No bias needed as the Batch Norm handles it\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "        )\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv1d(64, 64, kernel_size=3, padding=1, stride=1, bias=False),  # No bias needed as the Batch Norm handles it\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool1d(4)\n",
        "        )\n",
        "        self.spatial_layer = nn.Sequential(\n",
        "            nn.Conv1d(64, 12, kernel_size=3, padding=1, stride=0, bias=False),  # No bias needed as the Batch Norm handles it\n",
        "            nn.BatchNorm1d(c_out),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(in_features=1216, out_features=608),  # No bias needed as the Batch Norm handles it\n",
        "            nn.BatchNorm1d(608),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2)\n",
        "        )\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(in_features=608, out_features=304),  # No bias needed as the Batch Norm handles it\n",
        "            nn.BatchNorm1d(304),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2)\n",
        "        )\n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(in_features=304, out_features=10),  # No bias needed as the Batch Norm handles it\n",
        "            nn.BatchNorm1d(10),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2)\n",
        "        )\n",
        "        self.flat = nn.Flatten()\n",
        "        \n",
        "        self.gradients = None,\n",
        "\n",
        "        self.maxxy  = nn.MaxPool1d(4)\n",
        "\n",
        "        # hook for the gradients of the activations\n",
        "    def activations_hook(self, grad):\n",
        "        self.gradients = grad\n",
        "\n",
        "    # def forward(self, x):\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = self.layer4(x)\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = self.layer5(x)\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = self.layer6(x)\n",
        "\n",
        "        print(x.shape)\n",
        "        x = self.maxxy(x)\n",
        "\n",
        "        x = self.flat(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        x = nn.Softmax(dim=1)(x)\n",
        "\n",
        "        # x = x.argmax(1)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def get_activations_gradient(self):\n",
        "        return self.gradients\n",
        "    \n",
        "    def get_activations(self, x):\n",
        "        return self.features_conv(x)\n",
        "\n",
        "\n",
        "my_nn = myModule(12 , c_out = 1)\n",
        "my_nn = my_nn.double()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name, param in my_nn.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFzymFsjl3W4"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "learning_rate = 0.001\n",
        "num_epochs = 50\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(my_nn.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del X\n",
        "del Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZpZ0b__yl3W4",
        "outputId": "40b69917-0144-4df6-b3b3-a9bd28d057be"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "for epoch in range(num_epochs):\n",
        "    my_nn.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = my_nn(inputs)\n",
        "        loss = loss_fn(outputs.float(), labels.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twr2wcbMLbk7",
        "outputId": "daf4e4ab-d06b-4c9b-a91b-125b634de249"
      },
      "outputs": [],
      "source": [
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0lwPvqil3W4"
      },
      "outputs": [],
      "source": [
        "my_nn.eval()\n",
        "pred_probab = my_nn(X_train[201:400])\n",
        "output = pred_probab.argmax(1)\n",
        "correct = (output == Y_train[201:400])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXiSjCWm38WJ",
        "outputId": "d600e960-191f-4173-e98f-3616e8fcb331"
      },
      "outputs": [],
      "source": [
        "accurate = 0\n",
        "total = 0\n",
        "for i in correct:\n",
        "  if(i):\n",
        "    accurate += 1\n",
        "  total += 1\n",
        "acc = (accurate/total)*100\n",
        "print(\"Accuracy = \" + str(acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Accuracy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_probab = my_nn(X_test[150:300])\n",
        "output = pred_probab.argmax(1)\n",
        "correct = (output == Y_test[150:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "accurate = 0\n",
        "total = 0\n",
        "for i in correct:\n",
        "  if(i):\n",
        "    accurate += 1\n",
        "  total += 1\n",
        "acc = (accurate/total)*100\n",
        "print(\"Accuracy = \" + str(acc) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FYBOOa1_jWg"
      },
      "outputs": [],
      "source": [
        "#Saving the model parameters. Parameters are saved, hence Don't run \n",
        "\n",
        "PATH1 = 'physionet/my_nn.txt'\n",
        "PATH2 = 'physionet/my_nn2.txt'\n",
        "torch.save(my_nn.state_dict(), PATH1)\n",
        "torch.save(my_nn, PATH2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0PCdQlVBGWy"
      },
      "outputs": [],
      "source": [
        "PATH1 = 'physionet/my_nn.txt'\n",
        "model = myModule(12 , c_out = 1)\n",
        "model.load_state_dict(torch.load(PATH1))\n",
        "model.eval()\n",
        "model = model.double()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_train == 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index = [i for i ,e in enumerate(Y_train) if e == 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchcam.methods import GradCAMpp, SmoothGradCAMpp\n",
        "from scipy.interpolate import CubicSpline\n",
        "import seaborn as sns\n",
        "\n",
        "# i = 9\n",
        "# cams = GradCAMpp(model, [\"layer6\"])\n",
        "# out = model(X_train[i:i + 1])\n",
        "# cams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cam = cams(class_idx= 1,scores = out)\n",
        "# for t in cam:\n",
        "#   print(t.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# out.argmax(dim = 1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from scipy.interpolate import CubicSpline\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# large_array = (X_train[i][0].tolist())\n",
        "# small_array = np.array(cam[0].tolist()).reshape([77])\n",
        "\n",
        "# x_large = np.arange(len(large_array))\n",
        "# x_small = np.linspace(0, len(large_array), len(small_array))\n",
        "\n",
        "# plt.plot(x_large, large_array, label='Large Array')\n",
        "\n",
        "# cubic_interpolator = CubicSpline(x_small, small_array)\n",
        "# interpolated_data = cubic_interpolator(x_large)\n",
        "\n",
        "# # Overlay the heatmap of the smaller array\n",
        "# plt.scatter(x_small, small_array, c=small_array, cmap='hot', s=100, alpha=0.7, label='Heatmap')\n",
        "# # for i, val in enumerate(small_array):\n",
        "# #     plt.vlines(x_small[i], ymin=np.min(large_array), ymax=val, colors='red', linewidth=2, alpha=0.5)\n",
        "\n",
        "# # Add colorbar for the heatmap\n",
        "# cbar = plt.colorbar()\n",
        "# cbar.set_label('Heatmap Intensity')\n",
        "\n",
        "# # Add labels and legend\n",
        "# plt.xlabel('SmoothGradCAMpp')\n",
        "# plt.ylabel('Value')\n",
        "# plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in index:\n",
        "    cams = GradCAMpp(model, [\"layer6\"])\n",
        "    out = model(X_train[i:i + 1])\n",
        "    cam = cams(class_idx= 1,scores = out)\n",
        "\n",
        "    large_array = (X_train[i][0].tolist())\n",
        "    small_array = np.array(cam[0].tolist()).reshape([77])\n",
        "\n",
        "    x_large = np.arange(len(large_array))\n",
        "    x_small = np.linspace(0, len(large_array), len(small_array))\n",
        "\n",
        "    # plt.plot(x_large, large_array, label='Large Array')\n",
        "\n",
        "    cubic_interpolator = CubicSpline(x_small, small_array)\n",
        "    interpolated_data = cubic_interpolator(x_large)\n",
        "\n",
        "    sns.set(rc={'figure.figsize':(40,30)})\n",
        "\n",
        "    time_series_data = large_array\n",
        "\n",
        "    heatmap_data = interpolated_data\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    # Plot the time series data\n",
        "\n",
        "    ax1.plot(time_series_data, color='blue', label='Time Series Data')\n",
        "    ax1.set_ylabel('Time Series', color='blue')\n",
        "    ax1.tick_params(axis='y', labelcolor='blue')\n",
        "\n",
        "    # Create a second y-axis for the heatmap\n",
        "    ax2 = ax1.twinx()\n",
        "    sns.heatmap([heatmap_data], ax=ax2, cmap='coolwarm', cbar=False, alpha = 0.1)\n",
        "\n",
        "    # Set labels and title\n",
        "    ax2.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "    # Display the plot\n",
        "    plt.savefig('foo' + str(i) + '.png')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUIFP4EDB6Ut"
      },
      "outputs": [],
      "source": [
        "pred_probab = model(X_test[400:600])\n",
        "output = pred_probab.argmax(1)\n",
        "correct = (output == Y_test[400:600])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Zdw1ZkCArB",
        "outputId": "9bc503ed-e622-4565-8395-190baca4ba08"
      },
      "outputs": [],
      "source": [
        "accurate = 0\n",
        "total = 0\n",
        "for i in correct:\n",
        "  if(i):\n",
        "    accurate += 1\n",
        "  total += 1\n",
        "acc = (accurate/total)*100\n",
        "print(\"Accuracy = \" + str(acc) )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
